---
title: 豆瓣书影音记录导出到Notion并同步
categories:
  - work
tags:
  - Life
index_img: 'https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011207770.png'
abbrlink: 29092c2e
date: 2023-03-01 12:05:27
---

<!-- more -->
<!-- categories:Dev、Ops、Study、Sth、News、work-->
<!-- tags: 
Python、MySQL、LeetCode、机器学习、Linux、Big Data、Java、BlockChain、Docker、Web 、分布式、
Maven、数据结构、JVM、JavaScript、Crontab、Shell、Ubuntu、VPN、NodeJS、String、VM、Hadoop、
Life、树莓派、Git、Hexo、算法、运维、网络、看法、电影、美学、写作、哲学、文档、绘画、前端、
历史、政治、社会、导购
 -->
豆瓣标记条目导出到 Notion 并同步的一套操作和工具，并不适用于所有人。

## 原理

使用油猴脚本一键导出`看过/读过/听过/玩过`的电影、书、音乐、游戏、舞台剧条目。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202302281135997.png)

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202302281136741.png)

分别点击上面那五个“导出看过的”链接的话就会分别从

- `https://movie.douban.com/mine?status=collect`
- `https://music.douban.com/mine?status=collect`
- `https://book.douban.com/mine?status=collect`
- `https://www.douban.com/people/<people>/games?action=collect`
- `https://www.douban.com/location/people/<people>/drama/collect`

这几个地方自动翻页去获取个人标记数据（包括评分、评分时间以及短评）并最终导出 csv 文件。每次都可能需要一点时间给脚本去翻页获取数据，中途不要关掉浏览器，也不要在这个页面上去操作什么。因为这三个地方不是具体条目页面，页面访问 limit request 并不严格，所以这样跑脚本完全不会被当做机器人而遭到封禁 IP 或要求重新登录之类的。

但局限也就是这里无法准确获取更多有关条目本身的信息，比如电影条目的 IMDb 链接、制片国家，也无法精准把导演和演员之类的人名区分开。所以会发现导出的列表和最后实际使用中的 Notion table 的信息有对应不上的或者缺失的。这是正常的，也是无法避免的。 我个人的 Notion 示例看着数据是完整的，是因为最早尝试过自己写爬虫完整地爬取数据，但是数次遭遇被临时封禁`IP`并要求重新登录，整个过程很痛苦很麻烦，所以决定放弃爬虫方案了。

## 使用

Chrome浏览器中安装插件：油猴脚本 -> [豆瓣读书+电影+音乐+游戏+舞台剧导出工具](https://greasyfork.org/en/scripts/420999-豆瓣读书-电影-音乐-游戏-舞台剧导出工具)，安装后正常登录豆瓣，就可以在上面看到多出五个链接，“导出看过的”之类的。点击导出就可以导出`csv`到本地了。

### 导入

这是[模板集合](https://zhouyinglin.notion.site/49d4c3e1ec7f4f2dac3114f155374193)，选择自己需要的模板点击右上角的`Duplicate`，即可将模版复制到自己的 workspace 中。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202302281144164.png)

然后在新建的 `database `页面右上角菜单打开后选择 `Merge with CSV`，将第一步导出的 `csv` 文件进行导入，数据量较大的话可能需要一点时间。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202302281145437.png)

导入后效果：

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202302281145628.png)



因为我的油猴脚本导出的 csv 是这样的:

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202302281145921.png)

## 定时更新豆瓣动态至Notion

这么多年过去了，google reader 都死掉了，豆瓣的 RSS 依然还保留着。 在个人页面的右下角一直安静地存在着：

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011003918.png)

以[我的账号的 RSS 信息](https://www.douban.com/feed/people/139201735/interests)为例， 这个 feed 里只有书影音的标记信息，并且想看、在看、看过三类状态的信息也都包括。**缺点是仅有保留最新的 10 条信息。**更新方法就是定时读取这个 RSS feed，然后从中将新的标记信息自动更新到 Notion 里去，就很方便了。

### 获取仓库到自己账户

1. 注册github账号
2. fork[代码仓库](https://github.com/bambooom/douban-backup)

### 注册Notion API 集成

按照 [Notion 文档](https://developers.notion.com/docs/getting-started) 注册一个 Integration，叫什么名字随意，获取 一下Token。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011141637.png)

### 连接数据表格

点击Notion页面右上角三个点—Add connections，选择刚创建好的Integration连接，可以看到我这里已经连接上了。连接号之后，就可以通过Notion API来访问或更新数据了。注意，每个database都需要单独连接。连接好之后查看权限，是可以编辑的。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011141433.png)

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011014914.png)

### 配置secretes

代码仓库fork之后，就在自己账户里了，找到并打开`Settings-Security-Actions `,新增`secretes`，这里的`secretes`可以理解为密钥或者环境变量。根据这些参数来找到对应的对象。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011017689.png)

添加方法就是填写Key、Value，Key是写死在代码里的，就不用修改了，value按照具体的来填即可。由于我目前只记录了电影，所以只填了一个`NOTION_MOVIE_DATABASE_ID`，如果需要添加其他的，就按代码里`douban-backup/.github/workflows/sync-rss.js.yml`这个文件中定义的来添加databaseID 就行了

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011027695.png)

`DOUBAN_USER_ID`：本人的豆瓣ID，在豆瓣主页即可查到

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011021637.png)

`NOTION_MOVIE_DATABASE_ID`: Notion的Database ID，也就是所关联的数据表格的ID。注意 `?v=xxxx`这些不要加进去，就是中间红色方框那段纯字符串。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011024801.png)

`NOTION_TOKEN`： 就是Notion Integration Token

### 调整运行频率

这个脚本需要定时跑，也就是一个 cron job 而已，实现这个是靠 GitHub Actions 功能，[参考文档](https://docs.github.com/en/actions/reference/events-that-trigger-workflows#scheduled-events)。 GitHub 对免费用户的公开仓库暂时完全不会限制 Actions 的使用（Private repo 是有限制使用分钟数的），所以我在仓库里添加了这个 [workflow 设置文件](https://github.com/YuanZhou314/douban-backup/blob/main/.github/workflows/sync-rss.js.yml)。默认设置了24个小时跑一次，如果需要修改频率，就编辑这个workflow文件，将 24 改为 6 即表示每隔 6个小时就运行一次脚本。如果需要改为一天或几天，可以参考网上的cron表达式怎么写，粘贴进来就行了。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011034636.png)

### 测试

执行手动运行脚本可以测试该脚本，也可以在修改了脚本之后手动跑一下查看结果。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011042426.png)

这里可以查看脚本运行任务方面的具体日志。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/202303011044647.png)



### 注意事项

这个更新脚本获取下来的信息与上面模板的字段名、字段类型是一致的，不要改掉模板后再去跑脚本，这样就会赋值失败导致跑不起来。如果非要修改Notion模板字段信息，那就去代码中把字段信息也同步改了。但注意**字段类型不要修改**，除非你对这个项目很熟悉……

如果存在标题或者某个字段拉取不到，可以尝试重新新建一个表格试试。注意，更新表格后需要重新连接和修改`secrets`

转载自：https://zhuzi.dev/2021/06/05/douban-backup-sync-notion/
