---
title: 机器学习实践（一）：鸢尾花分类
date: 2022-08-06 20:34:30
tags: 
- 机器学习
- Python
categories: Study
index_img: https://raw.githubusercontent.com/YuanZhou314/PicRepo/main/imgs/old/jiqixuexi.png
---

<!-- more -->

### 一些概念

#### 机器学习的历史

人为指定决策规则。人为指定决策规则适合处理人们非常熟悉处理过程的应用，一旦数据量过大、数据处理过程复杂或者任务有所变化，就需要机器学习上场了。
早在19世纪的50到80年代，科学家们就有着让计算机算法代替人脑思考的想法，最初，机器学习只用于垃圾邮件清理，数学公式分析等简单领域，然而后来其应用场景越来越多，无论是图片过滤，语音分析，数据清洗等领域都能看到机器学习的身影。到如今无论是智能手机，航空运输，智能驾驶等方方面面都可以看到 AI 的身影

机器学习主要应用数据科学领域，它与普通程序开发的主要区别在于一般程序，数据往往来源于不同的数据库，通过对数据进行复杂转化，运算得到最后的结果。而机器学习目的并不是为了得到最后的运算结果，而是对计算过程进行分析，总结出一套运算的规则。只要数据量足够多，运算规则就越准确。最后可以根据这套规则对没有通过验证的数据进行预算，得到预算后的值。只要使用的规则正确，预算的结果的正确率往往可以达到95%以上。

深度学习开始只是机器学习的一分支领域，它更强调从连续的层中进行学习，这种层级结构中的每一层代表不同程序的抽象，层级越高，抽象程度越大。这些层主要通过神经网络的模型学习得到的，最大的模型会有上百层之多。而最简单的神经网络分为输入层，中间层（中间层往往会包含多个隐藏层），输出层。
![](https://raw.githubusercontent.com/YuanZhou314/PicRepo/main/imgs/20220806203500.png)

#### 机器学习

##### 监督学习

用户将输入和预期输出提供给算法，算法根据给定输入给出预期输出。这里的"监督"就是样例的预期输出，这个输出“监督”着算法。监督学习算法需要提供大量数据

- 识别信封上手写的邮政编码
- 基于医学影像判断肿瘤是否为良性
- 检测信用卡交易中的诈骗行为
  常见的监督学习包含了线性回归、k近邻、朴素贝叶斯分类 、决策树、随机森林与梯度提升决策树、支持向量机等多种算法，

##### 无监督学习

只有输入数据已知，没预期的输出数据。理解和评估此类算法比较困难，例如

- 分析一些列博客文章的主题
- 将客户分类为具有相似偏好的群组
- 检测网站的异常访问模式

常见的无监督学习分为聚类、降维两大类，包含了PCA（主成分分析）、NMF（非负矩阵分解）、t-SNE（流形学习）、k均值聚类、DBSCAN 等多种算法

机器学习中的每个实体或每一行称为样本or数据点，每一列或者描述实体的属性成为特征。

构建机器学习解决方案需要注意的点：

- 我的问题是什么？已经收集到的数据能够回答这个问题了吗？
- 我的问题如何表达成机器学习问题？
- 我收集的问题是否足够表达我想解决的问题？
- 提取了数据的哪些特征？这些特征是否能实现真正的预测？
- 如果预测应用是否成功？
- 这个解决方案与商业产品中的其他部分是如何影响的？

------

### 各项工具

（版本均未指定，默认最新）

scikit-learn：机器学习库，包含各种算法

NumPy：科学计算的基础包，包括各种数组，数学函数等，在机器学习中主要用到的是，将NumPy数组格式的数据传给算法

SciPy：科学计算的函数集合，包含线性代数高级程序、特殊函数函数和统计分布等。在这里主要用到scipy.sparse输出稀疏矩阵（大部分元素为0，非0元素分布无规律）

Matplotlib：科学绘图库，可生成数据的可视化内容

Pandas：处理和分析数据的库，基于DataFrame的数据结构，类似一个Excel表格，pandas中包含各种操作这个数据结构的API，还可以提取各种文件格式和数据库中的数据

mglearn：《Python机器学习基础教程》书本自带库，用于美化绘图

------

### 鸢尾花分类

数据来源：**内置在sklearn的datasets中**，由load_iris()函数获取

```python
from sklearn.datasets import load_iris
datas=load_iris()
```

数据内容（主要）

data：样本数据，格式为Numpy数组。例如：[5.1 3.5 1.4 0.2]，每行数据代表一朵花的测量数据

target：测量过的每朵花的品种，同样是一维Numpy数组。对应data中的每一行数据所测得的结果

target_names：想要预测的花的品种，target中的结果对应着这里的names。是一个字符串数组

feature_names：对每个特征进行说明，对应data中的各个属性。字符串数组

![](https://raw.githubusercontent.com/YuanZhou314/PicRepo/main/imgs/20220806203517.png)

DESCR：数据集的简要说明，类似备注

**规划数据：测试集**

注意：不能用训练的数据来测试模型，因为模型会记住训练时用的数据集，所以会100%“预测”结果，这无法评估模型的泛化（预测）能力，应该使用测试数据集，确保这些数据集模型之前从未见过。一般的做法是将原有的数据集拿出25%作为测试用

train_test_split函数会将数据集打乱后，按照比例分割给X_train, X_test, y_train, y_test四个子集，X_train包含75%，X_test为25%，调用子集的shape()函数可看到数量

```bash
X_train, X_test, y_train, y_test = train_test_split(datas['data'], datas['target'], random_state=0)
```

**检查数据：可视化**

Ps:反正没怎么能看懂这些生成的图~在预测测试数据时应该是非必要的

```bash
将需要可视化的数据转成DataFrame
iris_dataframe=pd.DataFrame(X_train, columns=datas.feature_names)

grr = pd.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)
#执行绘制
plt.show()
```

**训练数据：基于训练构建模型**

k近邻算法：在训练集中寻找与新数据点距离最近的数据点，将找到的数据点的标签赋值给新数据点，达到预测效果，k的含义指训练集与新数据点中最近的任意k个邻居，利用邻居中数量最多的类别做预测

```makefile
#创建KNeighborsClassifier的实例，算法就封装在实例中，这里只需设置邻居为1即可
knn=KNeighborsClassifier(n_neighbors=1)
#构建基于训练的模型，fit函数返回的信息无需关注，它只修改了knn对象
knn.fit(X_train, y_train)
```

**预测数据**

将新的数据传入模型，模型会预测出结果

```lua
#将样本数据封装成numpy数组
X_new = np.array([[5,2.9,1,0.2]])

#封装好的数组传给knn的predict函数进行预测
prediction=knn.predict(X_new)

#查看预测结果和结果在target中对应的品种
print(prediction)
print(datas['target_names'][prediction])
```

**评估模型**

预测测试数据集，并和已知的品种进行对比，就可以计算出精度，从而衡量模型的优劣

```python
#需要用到之前的测试集
y_pred=knn.predict(X_test)

#计算精度1
print('预测比例：{:.2f}'.format(np.mean(y_pred == y_test)))

#计算精度2
print('预测比例：{:.2f}'.format(knn.score(X_test, y_test)))
```

问题：数据分测试集这部分没有看懂
