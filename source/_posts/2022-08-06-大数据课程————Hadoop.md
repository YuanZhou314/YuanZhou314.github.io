---
title: 大数据课程————Hadoop
date: 2022-08-06 19:42:32
tags:
- Big Data
- Hadoop
categories: Study
index_img: https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/BigData.jpg
---

<!-- more -->

**hadoop搭建**：

1. 环境搭建：利用分发脚本在所有服务器上部署java和hadoop
2. 组件部署：三个重要组件分别部署在三台服务器上，并修改配置文件
3. 启动集群并测试功能：格式化后分别启动组件并上传文件，配置历史服务器和日志功能

 

**服务器相关概念**

类型：文件服务器、数据库服务器、WEB服务器

特点：高处理能力、高扩展性、高可靠性

服务器磁盘

机械硬盘：

SCSI接口硬盘，早期使用，已停售，1w转/min

SAS接口硬盘：提升，1.5w转/min

STAT硬盘：串口硬盘，主流硬盘带纠错、降噪功能，7200转/min

固态硬盘：

SSD硬盘：贵，性能高

交换机：

存储转发设备，交换式集线器，扩展端口功能、物理编址……

网卡：

以太网网卡，PCI总线接口服务器一般使用千兆网卡

机架：

存储服务器主机的机柜。通信使用交换机

IDC数据中心：

电信部门为企业做托管

Radi磁盘阵列：

独立磁盘冗余阵列，最新的Raid5，将校验的数据分布在所有磁盘上，基本满足大部分需求，主流用品

 

**Hadoop**

概念：分布式系统基础架构，主要解决海量数据的存储和分析计算，广义上指的是Hadoop生态圈

 

**三大发行版本**

Apache：基础版本（2006）

Cloudera：继承大数据框架，产品CDH（2008）

Hortonworks：文档较好，HDP（2011）

 

**优势**：

高可靠性，底层多个数据副本，某计算单元故障不会丢失

高扩展性，集群间分配任务数据，动态扩展节点

高效性，Hadoop是并行工作，加快任务处理速度

搞容错性，自动将失败的任务重新分配

 

**Hadoop 1.x、2.x和3.x**

1.x：MapReduce（计算+资源调度）；HDFS（数据存储）；Common（辅助工具）

2.x：MapReduce（计算）；Yarn（资源调度）；HDFS（数据存储）；Common（辅助工具）

3.x：在组成上和2代没有区别，有其他区别

 

 

**HDFS架构**

NameNode（nn）：存储文件的元数据，如文件名、目录结构、文件属性，以及每个文件的块列表和块所在的DataNode

DataNode（dn）:在本地文件系统存储文件块数据，以及块数据的校验和

Secondary NameNode（2nn）：每隔一段时间对nn元数据备份

 

**YARN架构概述**

另一种资源协调者，是Hadoop的资源管理器

Resourceanager（RM）：整个集群资源（内存CPU等）的总管，存在多个客户端提交job让其运行

NodeManager（NM）：单个节点服务器的资源老大，一个节点可有多个Container

ApplicationMaster（AM）：单个任务运行的老大

Container：容器，相当于一台独立的服务器，封装了任务运行所需的内存CPU磁盘网络等

 

**MapReduce架构**

MapReduce将计算分为两个阶段：Map和Reduce，Map阶段是并行处理输入数据，Redce是对Map结果进行汇总

 

**HDFS、YARN、MapReduce三者关系**

HDFS是基础的架构，NameNode记录元数据，DataNode是存储单元，2nn负责备份数据。客户端向集群提交一个任务，YARN中的ResourceManager会寻找其中一个节点服务器的NodeManager，开启一个Container，将任务放在ApplicationMaster中运行，AM向RM申请运行资源，在节点中寻找到合适资源后开启资源，由AM开启MapTask，这就是Map阶段，每一个MapTask独立工作，检索后返回结果写入磁盘上，形成一个ReduceTask，NameNode再次进行记录操作

 

**大数据生态体系**

 

数据来源层：数据库（结构化）、文件日志（半结构化）、视频、PPT等（非结构化）

数据传输层：Sqoop数据传递、Flime日志收集、Kafka消息队列（也可整理结构化与非结构化）

数据存储层：HDFS文件存储（结构、非结构）、HBase（非结构）

资源管理层：YRAN资源管理

数据计算层：MapReduce（离线计算、Hive数据查询）、SparkCore（内存计算、SparkMlib数据挖掘、SparkSql数据查询、SparkStreaming、Flink实时计算）

任务调度：Oozie任务调度、Azkaban任务调度器

整个数据平台的调度者：Zookeeper

业务层：叶树模型、数据可视化、业务应用

 

案例：在电商购买推荐的商品：用户操作——Nginx埋点获取访问日志——产生数据存储至文件日志——Flume日志收集——Kafka进行缓冲——Flink云计算并返回结果至数据库——后台读取分析数据，并返回推荐页给用户

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/20220806193819.png)

 

前置工作：

VM虚拟机、linux初始化、XShell远程等

磁盘分区：/boot分1G，/swap分4G，/分45G，装好之后给虚拟机创建初始快照

 

设置固定IP网关DNS：

vi /etc/sysconfig/network-scripts/ifcfg-ens33

将DHCP改成static

末尾添加

IPADDR=192.168.200.10x

GATWAT=192.169.200.2

NDS1=192.168.200.2

 

vi /etc/hosts 末尾添加：

192.168.200.100 hadoop100

192.168.200.101 hadoop101

192.168.200.102 hadoop102

192.168.200.103 hadoop103

192.168.200.104 hadoop104

192.168.200.105 hadoop105

------------------------------------虚拟机快照由此结束-------------------------------------

 

虚拟机基础工具：

yum install -y epel-release安装应用商店

yum install -y net-tools安装工具包

yum install -y vim 安装vim

 

添加部署java和hadoop

tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module解压java

tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/解压hadoop

 

前往/etc/profile.d新建my_env.sh脚本，脚本中加入java、hadoop环境变量

```bash
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

添加后source /etc/profile即可

 

hadoop文件分析

hadoop/bin目录中存储和HDFS、Yran、Mapred相关执行文件

hadoop/etc/hadoop目录中存储的xx-site.xml、workers相关

hadoop/sbin目录中一些集群功能开关相关脚本

hadoop/lib/native目录中存储的本地动态链接库，压缩功能会需要

 

**hadoop运行模式**

- Local (Standalone) Mode linux本地存储模式，一般测试用，企业不会用
- Pseudo-Distributed Mode 伪分布式模式，数据存储在HDFS上
- Fully-Distributed Mode 完全分布式模式，公司一般使用的

 

scp拷贝文件至其他服务器，首次迁移使用

基本语法：

scp：命令，实现服务器与服务器之间的拷贝

 -r ：递归

pdir/pdir/fname：源文件地址路径/名称

user@user@host:pdir/pdir/fname：目的地用户@主机：目的地路径/名称

例如：

scp -r ./jdk1.7/ root@hadoop103:/opt/module（将102本地推送至103），或

scp -r root@hadoop103:/opt/module/jdk1.7/ ./module（将远端102拉取至103）

rsync同步文件至其他服务器，速度较快，修改文件后使用

基本语法：

rsync：命令，实现服务器与服务器之间的文件同步

 -av：归档拷贝并显示复制过程

例如：

rsync -av hadoop-3.1.3/ root@hadoop103:/opt/module/hadoop-3.1.3/ 将本地hadoop文件同步至103上

注意：需要双方同时安装了rsync才可以执行操作

 

**利用rsync实现同步分发** 格式：xsync xxx，即可分发至所有指定服务器

注意：想要全局使用xsync必须满足以下条件：

1. 文件为可执行文件，即授权777

2. 将xsync上层路径添加至全局环境变量中，即/etc/profile，但这个文件千万不能乱改，否则出了cd其他命令都会失效，补救方法如下：

3. 1. 初始化path：export PATH=/usr/bin:/usr/sbin:/bin:/sbin:/usr/X11R6/bin
   2. 使用vi重新修改PATH，将错误的地方改掉：/bin/vi /etc/profile ，并重新source /etc/profile

脚本代码：

```bash
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
    echo Not Enough Arguement!
    exit;
fi
#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
    echo ====================  $host  ====================
    #3. 遍历所有目录，挨个发送
    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)
                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
```

 

该脚本缺陷：ssh时需要重复验证密码，不能一次到位，相当麻烦。因此需要使用ssh免登录

 

**ssh免密登录**

   普通情况下通过ssh其他服务器需要输入目标服务器密码，但也可以通过密钥来实现免密登录（注：未主动使用ssh命令的机器没有.ssh文件）

1. 在当前用户下的.ssh/下输入ssh-keygen -t rsa注册密钥，则在.ssh/下生成id_rsa私钥和id_rsa.pub公钥，还有一个存放目标节点的公钥集合文件known_hosts
2. 输入ssh-copy-id xxxx将公钥拷贝至目标服务器，首次需要输入密码，以后即可无密访问。若想访问服务器本身，也许这样操作

- 被无密访问过的服务器会在.ssh/生成一个authorized_keys文件，存放允许访问它的服务器；而known_hosts存放着它能够无密访问的其他服务器
- 主动无密访问其他节点的服务器才会有密钥

注意：防火墙关闭（centOS7）：

查看防火墙状态： systemctl status firewalld

永久关闭防火墙： systemctl disable firewalld

重启防火墙： systemctl enable firewalld

关闭防火墙开机自启： systemctl disable firewalld.service

 

集群部署规划

原则：NameNode、SecondaryNameNode和ResourceManager很耗内存，不要安装在同一个台机器上

 

|      | hadoop102        | hadoop103                  | hadoop104                 |
| ---- | ---------------- | -------------------------- | ------------------------- |
| HDFS | NameNodeDataNode | DataNode                   | SecondaryNameNodeDataNode |
| YARN | NodeManager      | ResourceManagerNodeManager | NodeManager               |

默认配置文件：官网下载，存放在Hadoop的jar包中

自定义配置文件：$HADOOP_HOME/etc/hadoop位置下的core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml文件

根据自己需要，参照默认配置文件，将自定义配置文件修改

 

配置集群

- 核心配置文件core-site.xml

```xml
<!-- 指定NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop102:8020</value>
    </property>
    <!-- 指定hadoop数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>
    <!-- 配置HDFS网页登录使用的静态用户为root -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>root</value>
    </property>
```

- HDFS配置文件 hdfs-site.xml

```xml
<!-- nn web端访问地址-->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop102:9870</value>
    </property>
    <!-- 2nn web端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
```

- YARN配置文件yarn-site.xml

```xml
<!-- 指定MR走shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 指定ResourceManager的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>
    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
```

- MapReduce配置文件 mapred-site.xml

```xml
<!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
```

- $HADOOP_HOME/etc/hadoop/woekers中的localhost改成

```
hadoop102
hadoop103
hadoop104
```

- 使用分发脚本xsync将当前改动分发至所有服务器

**启动集群**

首次启动集群需要使用hdfs namenode -format进行格式化，注意格式化必须停止所有进程（stop-all.sh）并删除所有机器的data和logs目录，再进行格式化

 

- 启动HDFS：sbin/start-dfs.sh

此处教程是用子用户操作的，而我这边直接用在root下操作，所以有些地方需要修改

针对root用户的问题，在start-dfs.sh，stop-dfs.sh中分别添加

HDFS_DATANODE_USER=root

HDFS_DATANODE_SECURE_USER=hdfs

HDFS_NAMENODE_USER=root

HDFS_SECONDARYNAMENODE_USER=root

 

使用jps查看当前java相关的进程：

7281 Jps

6948 DataNode

6812 NameNode

浏览器输入[hadoop102:9870](http://hadoop102:9870/) 查看HDFS上存储的数据信息

 

- 在配置了ResourceManager的服务器中启动YARN：sbin/start-yarn.sh

同样针对root用户，在start-yarn.sh和stop-yarn.sh中添加

```xml
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
```

用jps查看yarn节点中的进程

2609 DataNode

3089 NodeManager

3420 Jps

2958 ResourceManager

浏览器中输入[hadoop103:](http://hadoop102:9870/)8088 查看YARN运行的job信息 

 

**集群基本测试**

- 上传文件到集群

​     hadoop fs -mkdir /input 在/目录下创建一个input文件夹

​     hadoop fs -put $HADOOP_HOME/wcinput/word.txt /input 将word.txt上传到/input下

- 查看HDFS文件存储路径

​     不太清楚是什么原因，教程中的文件在102、103和104中都各自存了一份，而我的文件却只有在104是完整的，103是不完整的，102就压根没有这个文件夹。在103和104中，在104确实是能够cat出来看到源文件的上传的文件分成多个文件块存储在一起，文本文件可直接cat查看，gz压缩包则需要使用cat输出重定向至当前文件夹，然后才可正常解压：cat xxx>> xxx.tar.gz

 

问题：web端尝试删除上传的文件时，出现“Permission denied: user=dr.who, access=READ_EXECUTE, inode="/user":root:supergroup:drwx-wx-wx”。这样的话直接在core-site.xml中添加以下配置即可

```xml
<!-- 当前用户全设置成root -->
<property>
   <name>hadoop.http.staticuser.user</name>
   <value>root</value>
</property>
<!-- 不开启权限检查 -->
<property>
 <name>dfs.permissions.enabled</name>
 <value>false</value>
</property>
```



 

问题警告：

1. 存储位置会跳来跳去，不是固定是3等份！！！！但是删除后又好了，原因不明，新问题是元数据重新压缩后解压出现错误，原因不明
2. 有出现过上传的文件只在102中有，103和104找不到的情况，还有web页面打不开（已解决，防火墙的问题，关闭后需要重启）。

![](https://blog-cnd-1307088890.cos.ap-guangzhou.myqcloud.com/20220806194109.png)

 

- 运行hadoop自带的hadoop-mapreduce-examples.jar来测试，将文件上传后预览

hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /wcinput /wcoutput

注意：

此处的wordcount是类似结果的变量（但在HDFS内没看到这个名字）

这里填写的是输入输出地址，即/wcinput 和 /wcoutput。其中**wcinput需要已存在于HDFS上，而wxoutput不能提前创建，否则会报错**。这个逻辑很奇怪，后面再看看什么原因，并且由于我分配的内存过小，在计算时有杀掉一些其他进程，导致无法预览，这个现在也不看，评论区有加内存的博客地址，需要的话随时去看

 

 

**集群崩溃处理办法**

先停止yarn和hdfs，再将所有集群节点的$HADOOP_HOME下的/data和/logs文件夹删除，最后重新格式化HDFS即可

sbin/stop-yarn.sh

sbin/stop-dfs.sh

rm -rf data/ logs/

hdfs namenode -format

注意：DataNode版本号相关，没听懂，与数据版本相关

 

**配置历史服务器与日志聚集功能**

历史服务器配置成功后，在程序运行完成后的yarn前端页面可查看其历史运行情况

日志功能配置成功后，可在历史运行情况页面打开logs，方便分析运行情况

 

在mapred-site.xml中添加以下参数后，分发至各个节点：

```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>
<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>
```

 

在yarn-site.xml中添加以下参数后，分发至各个节点：

```xml
<!-- 开启日志聚集功能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<!-- 设置日志聚集服务器地址 -->
<property>
    <name>yarn.log.server.url</name>
    <value>http://hadoop102:19888/jobhistory/logs</value>
</property>
<!-- 设置日志保留时间为7天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```



开启历史服务器和日志聚集功能之前，先将HDFS和YARN重启一遍，再在102中启动。启动后即可在jps中查看历史服务器进程，日志聚集不会产生进程，会从下次任务开始生成日志：

$HADOOP_HOME/bin/mapred --daemon start historyserver

 

HDFS/YARN的两种开关方式

- 整体开关：start/stop-dfs.sd；start/stop-yarn.sh
- 单节点开关：hdfs --daemon start/stop namenode/datanode/secondarynamenode；yarn ==daemon start/stop resourcemanager/nodemanager

**hadoop集群常用脚本**

- 集群组件开关脚本：统一开关HDFS、YARN、historyserver、logs

```bash
#!/bin/bash
if [ $# -lt 1 ]
then
    echo "No Args Input..."
    exit ;
fi
case $1 in
"start")
        echo " =================== 启动 hadoop集群 ==================="
        echo " --------------- 启动 hdfs ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"
        echo " --------------- 启动 yarn ---------------"
        ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
        echo " --------------- 启动 historyserver ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"stop")
        echo " =================== 关闭 hadoop集群 ==================="
        echo " --------------- 关闭 historyserver ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
        echo " --------------- 关闭 yarn ---------------"
        ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
        echo " --------------- 关闭 hdfs ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;
*)
    echo "Input Args Error..."
;;
esac
```



- 统一查看集群服务器状态

分发到各节点上之后，就可在任意一台节点查看各节点进程情况

```bash
#!/bin/bash
for host in hadoop102 hadoop103 hadoop104
do
        echo =============== $host ===============
        ssh $host jps
done
```



 

**hadoop常见端口号**

| 端口名称                  | Hadoop2.x   | Hadoop3.x        |
| ------------------------- | ----------- | ---------------- |
| NameNode内部通信端口      | 8020 / 9000 | 8020 / 9000/9820 |
| NameNode HTTP UI          | 50070       | 9870             |
| MapReduce查看执行任务端口 | 8088        | 8088             |
| 历史服务器通信端口        | 19888       | 19888            |

**常用配置文件**

hadoop3.x：core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml workers

hadoop2.x：core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml slaves


